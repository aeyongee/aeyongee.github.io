---
title: DAN25 네이버 컨퍼런스 Day2 후기
date: 2025-11-09 11:30:00 +0900
categories: [네트워킹, 컨퍼런스]
tags: [컨퍼런스]
---

안녕하세요!     
저는 네이버 컨퍼런스인 DAN25의 Day2 세션에 다녀왔습니다.  

![dan25 logo](/assets/post/IMG_7688.jpeg)

컨퍼런스 후기와, 들었던 세션에서 인상 깊었던 내용을 정리하고자 합니다 😁

<br>

## Day2 세션 신청과 NFT

Day1 신청은 10/27(월), Day2 신청은 10/28(화)에 진행되었는데요    
저는 Day2 신청만 하였고, 1분 이내로 마감되었습니다!    

신청을 완료하니까 네이버페이 앱에서 이런 NFT를 확인할 수 있었습니다.     

![NFT 티켓](/assets/post/IMG_7717.jpeg)

세션을 옮겨다니며 출입구에서 이 화면을 보여주는 것으로 입장권을 대체하였습니다.    

그런데 개인적으론,,, NFT로 티켓 발급받아서 더 편하다? 좋다? 는 잘 모르겠습니다    
(참가자 입장에서는 목걸이나 팔찌로 인증하는게 오히려 더 간편하다고 생각합니다)

![네비게이터 유형](/assets/post/IMG_7718.jpeg)

이건 MBTI 검사처럼 각자의 네비게이터 유형을 검사하는 게 있어서 해봤었는데요,
은근 저랑 비슷하게 나왔네요 ㅎㅎ 


<br>

## 컨퍼런스 규모와 부스

![naver dan25](/assets/post/IMG_7692.jpeg)

컨퍼런스는 코엑스 그랜드블룸에서 진행되었고, T1~T4는 1층에서, T5~T8은 2층에서 세션이 진행되었습니다. 세션 장소 간에 거리가 멀지 않아서 쉽게 이동할 수 있었습니다!

저는 올해 AWS에서 주최했던 AWS Summit Seoul에도 참여했었는데요,
확실히 써밋에 비하면 규모가 크진 않았습니다..! 

부스는 네이버 자사 제품들(웨일, 파파고, 네이버 쇼핑, 네이버지도 등)에 대한 체험을 할 수 있었는데, 개수가 많지 않아 1시간 이내로 빠르게 볼 수 있었습니다.

(이건 제가 체험한 부스 인증샷.)
![dopamin](/assets/post/IMG_7677.jpeg)


<br>

## 어떤 세션을 들었는지 ? - Day2

저는 총 5개 세션을 들었습니다!

1. 하루 수백억 건을 처리하는 똑똑한 로그 파이프라인 만들기: 비용·성능·안정성 삼박자
2. 기본기가 경쟁력이다 : 네이버가 Ncloud Storage를 만든 이유
3. 데이터 속 숨은 트렌드, LLM이 답하다 : 랭킹 기반 플레이스 트렌드 분석 시스템
4. 데이터 활용을 수 십 배 빠르게! KREAM의 데이터 Lakehouse 구축기
5. Multi-AI Agent 개발: 레퍼런스 아키텍처와 구현 전략

각 세션을 듣고 알게된 내용이나 인사이트를 짧게나마 남겨보겠습니다.


<br>

### 1️⃣ 하루 수백억 건을 처리하는 똑똑한 로그 파이프라인 만들기: 비용·성능·안정성 삼박자
> 네이버 검색 플랫폼_김완호

로그 파이프라인 Logiss 시스템에 대한 세션이었습니다.
기존의 로그 시스템엔 다음과 같은 문제가 있었다고 합니다.

1. 단일 토폴로지로 되어있어, 무중단 배포가 불가능
    - 배포 사전 공지와 새벽 작업이 필수이고, 부분 배포가 불가하여 전체 서비스 기능에 대해 배포 이후에만 확인 가능한 문제가 있었다고 합니다.
2. 낮/새벽 트래픽 차이
    - 네이버 전사로그는 일반적으로 트래픽이 낮 시간에 높고, 새벽시간에 유입이 적다고 합니다.
    - 가장 유입이 많은 peak 시간대 트래픽을 기준으로 클러스터 규모를 산정하여 리소스를 투입하기에, 새벽 시간에는 불필요한 리소스가 낭비된다는 문제가 있습니다.
3. 모든 로그의 공평한 처리
    - 로그의 중요도와 상관없이 데이터마다 설정된 최대 처리 속도로만 처리되었습니다.
4. 장기 저장소와 실시간 검색을 위한 저장소에 모두 전달
    - 두곳 모두 저장할 필요가 없거나, 트래픽 전체를 저장할 필요가 없는데도 불구하고 저장되는 경우가 존재하였습니다.

<br>

특히 1번 같은 경우엔 많은 공감이 되는 문제점이었습니다 😢     
위와 같은 문제를 해결한 방법은 다음과 같습니다! 

<br>

1. Storm Kafka Spout의 변경과 멀티 토폴로지를 도입
    - API 호출을 제거하고, assign 방식을 채택하였습니다.
    - 토폴로지 id를 바꿔 실행하면 토폴리지 갯수만큼 중복 처리하도록 하였습니다.
2. 낮 시간의 트래픽 일부를 새벽에 처리
3. 데이터의 중요도에 따라 로그 데이터 차등 처리
4. 저장소별로 정해진 비율만 저장


낮 시간에 몰리는 트래픽을 중요도에 따라 새벽 시간에 처리하도록 해결한 점이 인상깊었습니다. 대부분의 서비스가 낮 보다는 새벽 시간에 유입이 적을텐데, 이 방법을 잘 활용하면 리소스를 좀 더 효율적으로 사용할 수 있을 것 같다고 생각했습니다 !

성과 및 효과로는 무중단 배포가 실현되었고, 데이터의 실시간/비실시간 처리를 분리해서 트래픽을 분배하였고 우선순위 기반으로 처리하기에 핵심 서비스 영향을 최소화시켰다고 합니다.

<br>

### 2️⃣ 기본기가 경쟁력이다 : 네이버가 Ncloud Storage를 만든 이유
> NAVER Cloud Storage Tech_강영상

Ncloud Storage가 곧 출시된다고 합니다. 출시에 앞서, 어떤 서비스인지를 설명하고 어떻게 구현하였는지를 알려주는 세션이었습니다.

![ncloud storage](/assets/post/IMG_7683.jpeg)


네이버는 하루에도 대용량 데이터 요청이 들어오기 때문에 비용적 압박이 크다고 합니다.

기존에 다양한 네이버 스토리지(OwFS, Papyrus, Lemon, Bingo 등)이 있었는데, 비용 개선을 했는데도 여전히 높은 TCO를 개선해야하는 문제가 있었으며 외부 솔루션과 연동하려면 별도의 개발 및 관리가 필요하다는 문제 또한 존재하였습니다.

이러한 문제를 해결하고자 S3 API를 통해 Ncloud Storage를 개발하였으며, S3 API는 클라이언트/서버의 물리적 위치에 상관없이 무한 확장성을 갖고 있어서 사용하게 되었다고 합니다.

S3 API의 문서와 스펙이 너무나 방대해서, 이를 모두 개발할 수는 없었고 주요 API 20개를 선정하고 과거 논문과 사례 조사를 통해 핵심 기능 위주로 구현했다고 합니다.

그 이후엔 핵심 기능들에 대한 설명을 해주셨는데, 기존에 알고 있던 AWS의 S3과 개념이 거의 동일했습니다. 전 Ncloud Storage 만의 특별한 차별점이 있을 줄 알았어서, 그 점은 조금 아쉬웠던 것 같습니다.

이번달에 배포할 예정이고, 앞으로도 추가 기능 개발 예정이라고 하니 앞으로 어떤 기능이 추가될지 기대가 됩니다!!


<br>

### 3️⃣ 데이터 속 숨은 트렌드, LLM이 답하다 : 랭킹 기반 플레이스 트렌드 분석 시스템
> NAVER 플레이스 프로덕트_김현우, NAVER 플레이스 프로덕트_손재원

네이버지도 앱에서 발견 탭이 얼마전에 생겼는데, 이 서비스에 대한 세션이었습니다.

발견 탭은 실시간 트렌드, 컨텐츠 등 사용자의 니즈를 반영한 피드 형태의 서비스입니다. 사용자의 앱 체류 시간을 늘리는 것이 목표라고 합니다.

요로코롬...
![naver map](/assets/post/IMG_7719.jpeg)

제가 주로 쓰는 지도앱이 네이버지도이고, 요즘 이 발견 탭에서 맛집이나 핫플 정보를 많이 알게되서 이 세션에 관심이 가게 되었어요!!    


이 서비스는 실시간성, 랭킹, 설명가능성이 특징인데, 기존 랭킹은 단기 화제성을 반영하긴 어려웠다는 단점이 보완되었고, 왜 이 곳이 상위 랭킹인지를 알기 어렵다면 광고처럼 느껴지는 점을 보완하여 지금 뜨고 있는 이유를 기재하였다고 합니다.

연사 분께서 검색은 관심을 나타내고, 클릭은 좀 더 적극적인 행동을 나타내기에, 검색보다는 클릭이 훨씬 뚜렷하고 구체적인 관심도를 나타낼 수 있다고 하였습니다.

또한 실시간 서비스를 위해선 대용량 데이터를 빠르게 집계해야하는데, 단기지표는 데이터 오염에 민감하고 장기지표는 데이터 오염이 발생해도 전체적 지표에 영향은 미미하다는 특징이 있습니다. 

대규모 데이터를 효율적으로 실시간 집계하기 위해서는 집계 데이터의 캐시화가 필요합니다.

이를 위한 모델링의 아이디어는 다음과 같습니다.
1. 최신 트렌드일수록 높은 가중치를 부여합니다
2. 데이터에 동적 가중치를 설정합니다
3. 이유를 설명할 수 있어야 진짜로 인기 많은 것으로 간주합니다
    - 만약, 점수는 높지만 왜 인기가 있는지를 설명할 수 없다면 그 반대 케이스 업체에 가중치를 줘서 상위에 노출하는 방식!


그 다음으론 '이슈의 이유'를 찾는 키워드 뽑는 방식에 대해 설명해주셨습니다.

`로그 -> AI -> Keyword(decoding)`    
위 방식대로 키워드를 생성합니다.

BERTopic이란 여러 문서들이 갖고 있는 주제와 그 주제와 관련된 키워드를 찾는 모델링입니다.

미세 조정된 작고 효율적인 모델 sLLM이 거대 언어 모델인 LLM보다 텍스트 분류 작업에서 일관된 우수한 성능을 보입니다. sLLM은 주제어를 추출하고, 의미를 압축하는 것을 잘한다고 합니다!

그 대신에, 작은 모델을 사용할 때는 큰 모델이 같은 프롬프트에 대해서 어떻게 수행했는지를 알려줘야, 사용자가 의도한 대로 프롬프트를 수행한다는 특징이 있습니다.
(Instruction Distillation)

<br>

### 4️⃣ 데이터 활용을 수 십 배 빠르게! KREAM의 데이터 Lakehouse 구축기
> KREAM Service Backend_원찬경

KREAM에서 기존 데이터 분석 환경에서 데이터 LakeHouse로 구축한 사례에 대한 세션이었습니다.

기존 데이터 분석 환경은, 매일 새벽에 mysql -> mysql 로 덤프하였고, 사용자 행동 로그는 원본 로그를 분석 솔루션에 적재하고 이를 데일리 덤프하였다고 합니다.

Data LakeHouse는 데이터 웨어하우스와 데이터 레이크를 통합한 개념으로, 데이터 웨어하우스의 관리의 장점과, 데이터 레이크의 저장의 장점을 살린 시스템입니다.

레이크 하우스의 핵심은 테이블의 포맷인데, KREAM에서는 Apache Hudi와 Apache Iceberg 중에서 고민하였다고 합니다.

결국, Apache Iceberg를 채택하였는데 그 이유는 좀 더 유연하여 사후에 이것저것 고치기가 편하다는 것이 이유였습니다. 아무래도 유지보수 비용을 고려한 선택처럼 보였습니다!

결론적으론 구축 이후에, 약 140개의 DB 테이블이 1분~10분 내외로 동기화되며, 모든 데이터는 iceberg 테이블로 적재하여 지속적으로 성능을 최적화하고 있다고 합니다.

실제로 KREAM 사내 서버 엔지니어들은 대용량 통계 데이터를 준실시간 서빙하는 사례를 만들어냈는데, 서비스 내에 노출되는 통계 정보를 매시간 LakeHouse에서 계산하여 캐시로 서빙하였다고 합니다. DB 대신에 Trino로 대체하여 빠르기 집계할 수 있고, DB 부담도 완화되었다는 장점이 있습니다.

데이터를 관리하고 분석하는 시스템을 바꾸는 것만으로도, 사내 구성원들의 데이터 기반 의사결정 및 업무 생산성 향상에 크게 기여할 수 있다는 것이 놀라웠고, 좋은 사례로 느껴졌습니다!


<br>

### 5️⃣ Multi-AI Agent 개발: 레퍼런스 아키텍처와 구현 전략
> NAVER Cloud Tech Value Transformation_허창현

일단 저는 멀티 에이전트에 대해 잘 몰랐어서 관심이 갔던 세션입니다. 

단일 에이전트는 특정 역할을 수행하는 독립적인 에이전트입니다. 특정 업무에 최적화되어 있으며, 구현이 간단하고 빠르고 자원 소모가 적습니다.

그렇다면 멀티 에이전트는 무엇일까요?
말 그대로 특정 역할을 수행하는 다중 에이전트입니다.
하나의 문제에 대해 하나의 에이전트가 이를 해결하는 것이 아닌, 다소 복잡한 문제에 대해 에이전트 간 협업 및 분업하여 서로 피드백하여 해결합니다. 


다중 에이전트간 대화를 기반으로 동작하고, 자율적 협업 과 토론 기반으로 워크플로우를 자동화할 수 있다는 것이 인상적이었습니다. 에이전트끼리 '토론'한다는 게 재밌고 낯설게 느껴집니다 🤔


<br>


## 참가 후기
네이버에서 어떠한 문제점을 겪었을 때 어떻게 해결하였는지에 대한 사례 중심 세션들이 많았어서 만족했습니다! 👍    
저는 기술 중심의 세션보다는, 다른 회사에선 어떻게 문제를 해결하고 있는지가 궁금했는데 이번 컨퍼런스를 통해 많은 부분에서 궁금증이 해소되었습니다.

기억에 남는 것은 로그성 데이터에 대해 생각보다 중요하게 여긴다는 점이었습니다. 로그 데이터 관련 세션이 여러개 있었어서 사용자가 많은 서비스일수록 로그의 중요도가 높아지겠구나 라는 생각이 들었습니다.

내년에도 열리면 다시 참가하면 재밌을 거 같아요 😁


![alt text](/assets/post/IMG_7684.jpeg)


 
